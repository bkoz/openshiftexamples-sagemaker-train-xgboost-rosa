{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48b3b4cb-27a8-477b-8318-402869526d22",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "Machine Learning (ML) development using Open Data (ODH) Hub broswer-based Jupyter Notebooks on Kubernetes with Red Hat OpenShift on AWS (ROSA) enhanced with SageMaker Python SDK backed by S3 Storage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443f270d-be3d-4926-8da6-46a4461c570b",
   "metadata": {},
   "source": [
    "# Before you begin\n",
    "\n",
    "1. You need access to a [ROSA Cluster](https://cloud.redhat.com/blog/red-hat-openshift-service-on-aws-is-now-generally-available) with cluster-admin privileges in an available region [See Regions](https://docs.openshift.com/rosa/rosa_architecture/rosa_policy_service_definition/rosa-service-definition.html#rosa-sdpolicy-regions-az_rosa-service-definition).\n",
    "1. Your region needs to have SageMaker in the [available services](https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/).\n",
    "1. You need access to the AWS Console to create an IAM Execution role for [Amazon SageMaker Python SDK](https://sagemaker.readthedocs.io/en/stable/). [How to create an IAM Execution role](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html#sagemaker-roles-create-execution-role).\n",
    "1. You need to create AWS [credentials file for the AWS SDK](https://docs.aws.amazon.com/sdk-for-java/v1/developer-guide/setup-credentials.html).\n",
    "1. (Secure setup)[https://gist.github.com/dudash/33f4e385edeac2004306cd88f37e0f24]\n",
    "1. [Create an STS role](https://docs.openshift.com/rosa/rosa_install_access_delete_clusters/rosa-sts-creating-a-cluster-quickly.html)\n",
    "1. You need an S3 Storage Bucket with 'sagemaker' in the name and an Access Point. [How to create an S3 Storage Bucket with an Access Point]().\n",
    "1. You need a Project (or namespace). [How to create a project, add team members, set limits and quotas]().\n",
    "1. You need to deploy the ODH Operator in the namespace with 4 components: ODH Dashboard, JupyterHub, Jupyter Notebooks and ODH common. [How to deploy the Open Data Hub Operator]().\n",
    "1. Update the Jupyter Notebook Environment Variables prior to starting the Jupyter Notebook Server:\n",
    "    - AWS_REGION\n",
    "    - EXECUTION_ROLE_ARN\n",
    "    - S3_ENDPOINT_URL\n",
    "    - S3_ACCESS_KEY_ID\n",
    "    - S3_SECRET_ACCESS_KEY\n",
    "    - S3_BUCKET\n",
    "1. From the Jupyter Notebookterminal, run 'pip install -r requirements.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c30055e-01e1-4a06-9544-f702442c4794",
   "metadata": {},
   "source": [
    "From the Jupyter Control Panel, while selecting the notebook image and container size, set the environment variables below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccf6de44-fb4b-4f1b-986b-ad7ec66cab4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module Paths\n",
    "REQUIREMENTS = 'requirements.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ae2c92c-e3e9-4f4b-8e1d-460a39d47b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REQUIREMENTS}\n",
    "\n",
    "sagemaker\n",
    "tensorflow\n",
    "keras\n",
    "numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65bd137-2558-42eb-80cb-9625e5325292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO ODH notebooks use horus for dependency management, you must install requirements from terminal\n",
    "# TODO create ODH SageMaker Notebook image\n",
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0550dea5-7e11-4dc8-a4ae-cdfd9b8a01d8",
   "metadata": {},
   "source": [
    "## Verify your connection details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b45a176-bb5b-46eb-94fe-623af7101189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the below line to display the values for the Environment Variables. If not set, enter in the notebook image spawner prior to starting the server.\n",
    "#!env | grep 'AWS\\|S3\\|ARN' | sort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3f377b-7f0e-45f6-9b51-8aad1124b3c9",
   "metadata": {},
   "source": [
    "# Imports\n",
    "\n",
    "Amazon SageMaker Python SDK - is an open source library for training and deploying machine-learned models on Amazon SageMaker. With the SDK, you can train and deploy models using popular deep learning frameworks, algorithms provided by Amazon, or your own algorithms. https://sagemaker.readthedocs.io/en/stable/\n",
    "\n",
    "Boto3 - is the Amazon Web Services (AWS) Software Development Kit (SDK) for Python, which allows Python developers to write software that makes use of services like Amazon S3 and Amazon EC2. Boto3 is maintained and published by Amazon Web Services. https://github.com/boto/boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51367076-037f-431f-bf56-a6887bdccd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-08 20:39:08.748998: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-08 20:39:08.895296: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-08 20:39:08.895336: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-09-08 20:39:08.927616: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-09-08 20:39:09.709008: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-09-08 20:39:09.709117: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-09-08 20:39:09.709130: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# import AWS Sagemaker SDK \n",
    "import sagemaker\n",
    "\n",
    "# for the tf estimator model that is used to train with\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "# import the AWS SDK for python. \n",
    "import boto3\n",
    "\n",
    "# import os for misc. operating system dependent functionality\n",
    "import os\n",
    "\n",
    "# import numpy for common machine learning libraries like scikit-learn and SciPy\n",
    "import numpy as np\n",
    "\n",
    "# import keras for an open-source software library that provides a Python interface for artificial neural networks\n",
    "import keras\n",
    "\n",
    "# this module provide a few toy datasets (already-vectorized, in Numpy format) that can be used for debugging a model or creating simple code\n",
    "from keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14f6e673-2ab5-4b56-8ecb-3f1d700e08d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker 2.108.0\n",
      "Boto3 1.24.68\n"
     ]
    }
   ],
   "source": [
    "# print the imported versions\n",
    "print(\"SageMaker \" + sagemaker.__version__)\n",
    "print(\"Boto3 \" + boto3.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e8d825-ee7e-49db-9997-8295689eae60",
   "metadata": {},
   "source": [
    "## AWS Configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8e4ab3-3051-4782-996a-d769fd5189b6",
   "metadata": {},
   "source": [
    "### Set your region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "950b4d1d-e51c-4236-8a3f-e9316cb11037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# session manages interactions with the Amazon SageMaker APIs and any other AWS services needed.\n",
    "sess = sagemaker.Session(boto3.session.Session(region_name=os.getenv('AWS_REGION')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc8975b-adc9-4e31-a013-30e6408d16dd",
   "metadata": {},
   "source": [
    "### Set your IAM role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13275bbd-98f5-4842-9b04-7bc987cbc25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a role https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html\n",
    "\n",
    "# option 1: use for non-local deployments of SageMaker on systems where the AWS CLI and SageMaker CLI is deployed\n",
    "# role = sagemaker.get_execution_role()\n",
    "\n",
    "# option 2: manually set your IAM role arn for the Execution Role\n",
    "# if you need to find the arn, from a terminal with the AWS CLI type 'aws iam list-roles|grep SageMaker-Execution'\n",
    "# if you need to create or find the arn, for example, you'd go to https://us-east-1.console.aws.amazon.com/iamv2\n",
    "role = os.getenv('EXECUTION_ROLE_ARN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d58013-d4f4-4a47-af30-62c2f10d9c5d",
   "metadata": {},
   "source": [
    "## Configure the storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e88de76c-7431-4409-82f3-2d9f4ef94408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For S3 Storage\n",
    "# Edit this section using your own credentials\n",
    "# enter your region name\n",
    "s3_region = os.getenv('AWS_REGION')\n",
    "\n",
    "# enter your S3 endpoint URL\n",
    "s3_endpoint_url = os.getenv('S3_ENDPOINT_URL')\n",
    "\n",
    "# enter your S3 access key ID\n",
    "s3_access_key_id = os.getenv('S3_ACCESS_KEY_ID')\n",
    "\n",
    "# enter your S3 secret access key\n",
    "# TODO make OCP secret\n",
    "# TODO OIDC identity\n",
    "s3_secret_access_key = os.getenv('S3_SECRET_ACCESS_KEY')\n",
    "\n",
    "# enter your S3 bucket name\n",
    "s3_bucket = os.getenv('S3_BUCKET')\n",
    "\n",
    "# configure boto S3 connection\n",
    "s3 = boto3.client('s3',\n",
    "                  s3_region,\n",
    "                  #endpoint_url = s3_endpoint_url,\n",
    "                  aws_access_key_id = s3_access_key_id,\n",
    "                  aws_secret_access_key = s3_secret_access_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c35e50-ee31-4712-9859-3315617f7958",
   "metadata": {},
   "source": [
    "### Test your S3 bucket connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad4ca6cd-c8f0-40b0-845b-2a8bde4a5ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '42PCZRV39DY480XN',\n",
       "  'HostId': '249stXAqgDTzFFPvOhK7v5sf9ploTwnZXMwDRp+p/0Uw8Ua4zSCX04YgDR0z7UDsPc35m8D6PAY=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': '249stXAqgDTzFFPvOhK7v5sf9ploTwnZXMwDRp+p/0Uw8Ua4zSCX04YgDR0z7UDsPc35m8D6PAY=',\n",
       "   'x-amz-request-id': '42PCZRV39DY480XN',\n",
       "   'date': 'Thu, 08 Sep 2022 20:39:17 GMT',\n",
       "   'content-type': 'application/xml',\n",
       "   'transfer-encoding': 'chunked',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'Buckets': [{'Name': 'managed-velero-backups-fd20f621-126d-4995-a63e-ff038a92f3e3',\n",
       "   'CreationDate': datetime.datetime(2022, 9, 8, 20, 7, 35, tzinfo=tzlocal())},\n",
       "  {'Name': 'rosa-jjfzd-dbxd8-image-registry-us-east-2-vbfctdmjcqefdgxpdcns',\n",
       "   'CreationDate': datetime.datetime(2022, 9, 6, 21, 45, 34, tzinfo=tzlocal())},\n",
       "  {'Name': 'sagemaker-tf-estimator-model',\n",
       "   'CreationDate': datetime.datetime(2022, 9, 8, 15, 6, 7, tzinfo=tzlocal())}],\n",
       " 'Owner': {'ID': '156653ec7d02f798caa7bb60dd55fb03c097214374aa40e8dd4f9a66c5b3d34e'}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3.list_buckets()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368cfdd7-f9a1-41f0-87df-012cea2019ae",
   "metadata": {},
   "source": [
    "# Configure your Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49eb0b70-377a-4815-9108-16b12203f770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train is the data and y_train is the label\n",
    "# x_val is the data and y_val is the label\n",
    "(x_train, y_train), (x_val, y_val) = fashion_mnist.load_data()\n",
    "\n",
    "# create a directory called 'data' to store your datasets\n",
    "os.makedirs(\"./data\", exist_ok = True)\n",
    "\n",
    "# save the training data and label to the training folder\n",
    "np.savez('./data/training', image=x_train, label=y_train)\n",
    "\n",
    "# save the validation data and label to the validation folder\n",
    "np.savez('./data/validation', image=x_val, label=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61324e3b-2f3c-447d-8142-ca88d067ba16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the training path for the data\n",
    "training_input_path = './data/training.npz'\n",
    "# for local storage\n",
    "#training_input_path = './data/training.npz'\n",
    "\n",
    "# set the validation path for the data\n",
    "validation_input_path = './data/validation.npz'\n",
    "# for local storage\n",
    "#training_input_path = './data/validation.npz'\n",
    "\n",
    "# Set the location to store the trained model\n",
    "output_path = os.getenv('S3_BUCKET')\n",
    "# for local storage\n",
    "# create a directory called 'model' to store your model\n",
    "#os.makedirs(\"./model\", exist_ok = True)\n",
    "#output_path = './model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f363317-1a07-4184-900d-46486c92d28f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must setup local AWS configuration with a region supported by SageMaker.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# list of parameters https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/sagemaker.tensorflow.html\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m tf_estimator \u001b[38;5;241m=\u001b[39m \u001b[43mTensorFlow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mentry_point\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmnist_keras_tf.py\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Path (absolute or relative) to the local Python source file which should be executed as the entry point to training\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mrole\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrole\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                       \u001b[49m\u001b[38;5;66;43;03m# The IAM Role ARN for the TensorFlowModel\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m                          \u001b[49m\u001b[43minstance_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# number of EC2 instances to use\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mframework_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m1.15\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# TF version to use for executing the training code\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mpy_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpy3\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# Python version to use for executing the model training code\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# hyperparameters used during training\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_path\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# S3 location where the checkpoint data and models can be exported during training\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m                          \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.8/site-packages/sagemaker/tensorflow/estimator.py:193\u001b[0m, in \u001b[0;36mTensorFlow.__init__\u001b[0;34m(self, py_version, framework_version, model_dir, image_uri, distribution, compiler_config, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m framework_version \u001b[38;5;129;01mand\u001b[39;00m version\u001b[38;5;241m.\u001b[39mVersion(framework_version) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m version\u001b[38;5;241m.\u001b[39mVersion(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.15\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    191\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menable_sagemaker_metrics\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mTensorFlow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimage_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m distribution \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     distribution \u001b[38;5;241m=\u001b[39m fw\u001b[38;5;241m.\u001b[39mvalidate_distribution(\n\u001b[1;32m    196\u001b[0m         distribution,\n\u001b[1;32m    197\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstance_groups,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    202\u001b[0m         kwargs,\n\u001b[1;32m    203\u001b[0m     )\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.8/site-packages/sagemaker/estimator.py:2913\u001b[0m, in \u001b[0;36mFramework.__init__\u001b[0;34m(self, entry_point, source_dir, hyperparameters, container_log_level, code_location, image_uri, dependencies, enable_network_isolation, git_config, checkpoint_s3_uri, checkpoint_local_path, enable_sagemaker_metrics, **kwargs)\u001b[0m\n\u001b[1;32m   2733\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m   2734\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2735\u001b[0m     entry_point: Union[\u001b[38;5;28mstr\u001b[39m, PipelineVariable],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2747\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2748\u001b[0m ):\n\u001b[1;32m   2749\u001b[0m     \u001b[38;5;124;03m\"\"\"Base class initializer.\u001b[39;00m\n\u001b[1;32m   2750\u001b[0m \n\u001b[1;32m   2751\u001b[0m \u001b[38;5;124;03m    Subclasses which override ``__init__`` should invoke ``super()``.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2911\u001b[0m \u001b[38;5;124;03m        :class:`~sagemaker.estimator.EstimatorBase`.\u001b[39;00m\n\u001b[1;32m   2912\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2913\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mFramework\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43menable_network_isolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_network_isolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2914\u001b[0m     image_uri \u001b[38;5;241m=\u001b[39m renamed_kwargs(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_uri\u001b[39m\u001b[38;5;124m\"\u001b[39m, image_uri, kwargs)\n\u001b[1;32m   2916\u001b[0m     validate_source_code_input_against_pipeline_variables(\n\u001b[1;32m   2917\u001b[0m         entry_point\u001b[38;5;241m=\u001b[39mentry_point,\n\u001b[1;32m   2918\u001b[0m         source_dir\u001b[38;5;241m=\u001b[39msource_dir,\n\u001b[1;32m   2919\u001b[0m         git_config\u001b[38;5;241m=\u001b[39mgit_config,\n\u001b[1;32m   2920\u001b[0m         enable_network_isolation\u001b[38;5;241m=\u001b[39menable_network_isolation,\n\u001b[1;32m   2921\u001b[0m     )\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.8/site-packages/sagemaker/estimator.py:543\u001b[0m, in \u001b[0;36mEstimatorBase.__init__\u001b[0;34m(self, role, instance_count, instance_type, volume_size, volume_kms_key, max_run, input_mode, output_path, output_kms_key, base_job_name, sagemaker_session, tags, subnets, security_group_ids, model_uri, model_channel_name, metric_definitions, encrypt_inter_container_traffic, use_spot_instances, max_wait, checkpoint_s3_uri, checkpoint_local_path, rules, debugger_hook_config, tensorboard_output_config, enable_sagemaker_metrics, enable_network_isolation, profiler_config, disable_profiler, environment, max_retry_attempts, source_dir, git_config, hyperparameters, container_log_level, code_location, entry_point, dependencies, instance_groups, **kwargs)\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    539\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstance_type local or local_gpu is only supported with an\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstance of LocalSession\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    541\u001b[0m         )\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 543\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_session \u001b[38;5;241m=\u001b[39m sagemaker_session \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mSession\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_job_name \u001b[38;5;241m=\u001b[39m base_job_name\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_job_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.8/site-packages/sagemaker/session.py:128\u001b[0m, in \u001b[0;36mSession.__init__\u001b[0;34m(self, boto_session, sagemaker_client, sagemaker_runtime_client, sagemaker_featurestore_runtime_client, default_bucket, settings)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlambda_client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettings \u001b[38;5;241m=\u001b[39m settings\n\u001b[0;32m--> 128\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mboto_session\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mboto_session\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43msagemaker_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msagemaker_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43msagemaker_runtime_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msagemaker_runtime_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43msagemaker_featurestore_runtime_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msagemaker_featurestore_runtime_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.8/site-packages/sagemaker/session.py:151\u001b[0m, in \u001b[0;36mSession._initialize\u001b[0;34m(self, boto_session, sagemaker_client, sagemaker_runtime_client, sagemaker_featurestore_runtime_client)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_region_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mboto_session\u001b[38;5;241m.\u001b[39mregion_name\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_region_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 151\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    152\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust setup local AWS configuration with a region supported by SageMaker.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    153\u001b[0m     )\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_client \u001b[38;5;241m=\u001b[39m sagemaker_client \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mboto_session\u001b[38;5;241m.\u001b[39mclient(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msagemaker\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    156\u001b[0m prepend_user_agent(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_client)\n",
      "\u001b[0;31mValueError\u001b[0m: Must setup local AWS configuration with a region supported by SageMaker."
     ]
    }
   ],
   "source": [
    "# list of parameters https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/sagemaker.tensorflow.html\n",
    "\n",
    "tf_estimator = TensorFlow(entry_point='mnist_keras_tf.py', # Path (absolute or relative) to the local Python source file which should be executed as the entry point to training\n",
    "                          role=role,                       # The IAM Role ARN for the TensorFlowModel\n",
    "                          instance_count=1,                # number of EC2 instances to use\n",
    "                          framework_version='1.15',        # TF version to use for executing the training code\n",
    "                          py_version='py3',                # Python version to use for executing the model training code\n",
    "                          hyperparameters={'epochs': 1},   # hyperparameters used during training\n",
    "                          model_dir=output_path            # S3 location where the checkpoint data and models can be exported during training\n",
    "                          )  \n",
    "\n",
    "                          #instance_type=ml.c4.xlarge      # Type of EC2 instance to use, for example, ‘ml.c4.xlarge’.\n",
    "                          #image_uri=123.dkr.ecr.us-west-2.amazonaws.com/my-custom-image:1.0 custom-image:latest,\n",
    "                          #distribution,                   # how to run distributed training for data or model parallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45b58b7-5d79-4593-a314-6d0a69220962",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
